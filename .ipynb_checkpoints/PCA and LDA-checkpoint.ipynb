{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fced69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"datasets/faces/s\" + str(i) for i in range(1, 41)]\n",
    "cnt = 0\n",
    "Data = np.zeros((400, 10304))\n",
    "labels = np.zeros((400, 1))\n",
    "for i in range(40):\n",
    "    labels[i * 10 : (i + 1) * 10] = i + 1\n",
    "for path in paths:\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        img = Image.open(path + \"/\" + file)\n",
    "        np_img = np.array(img)\n",
    "        np_img = np_img.flatten()\n",
    "        Data[cnt] = np_img\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57dbc1c",
   "metadata": {},
   "source": [
    "## Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 112\n",
    "image_width = 92\n",
    "\n",
    "fig, axs = plt.subplots(4, 10, figsize=(16, 10))\n",
    "\n",
    "# Flatten the array of axes\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(40):\n",
    "    image_array = np.reshape(Data[(i) * 10], (image_height, image_width))\n",
    "    axs[i].imshow(image_array, cmap=\"gray\")\n",
    "    axs[i].set_title(i + 1)\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f3dd6",
   "metadata": {},
   "source": [
    "## Spliting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Data[0::2]\n",
    "X_test = Data[1::2]\n",
    "y_train = labels[0::2]\n",
    "y_test = labels[1::2]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d15c2",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7615c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA(training_data, alpha):\n",
    "    # Compute the mean of the training data\n",
    "    mean_face = np.mean(training_data, axis=0)\n",
    "    # subtract the mean from the training data\n",
    "    training_data_centralized = training_data - mean_face\n",
    "    # compute the covariance matrix\n",
    "    cov_matrix = training_data_centralized @ training_data_centralized.T\n",
    "    # compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    # sort the eigenvectors descindigly by eigenvalues\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    # restore the original eigenvectors\n",
    "    eigenvectors_converted = training_data_centralized.T @ eigenvectors\n",
    "    # normalize the eigenvectors_converted\n",
    "    eigenfaces = eigenvectors_converted / np.linalg.norm(eigenvectors_converted, axis=0)\n",
    "    # compute the number of components to keep\n",
    "    sum = 0\n",
    "    no_components = 0\n",
    "    for i in range(len(eigenvalues)):\n",
    "        sum += eigenvalues[i]\n",
    "        no_components += 1\n",
    "        if sum / np.sum(eigenvalues) >= alpha:\n",
    "            break\n",
    "    # project the training data on the eigenfaces\n",
    "    return mean_face, eigenfaces[:, :no_components]\n",
    "\n",
    "\n",
    "mean_face, eigenfaces = get_PCA(X_train, 0.8)\n",
    "print(eigenfaces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f7048",
   "metadata": {},
   "source": [
    "## Projection Training Data and Test Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff68ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_Projected_data(training_data,testing_data,mean_face, eigenfaces):\n",
    "    X_train_centered = training_data - mean_face\n",
    "    X_train_projected = X_train_centered @ eigenfaces\n",
    "    X_test_centered = testing_data - mean_face\n",
    "    X_test_projected = X_test_centered @ eigenfaces\n",
    "    return X_train_projected, X_test_projected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51426ee2",
   "metadata": {},
   "source": [
    "## Plotting the first 5 eigen faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e01bd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, eigenfaces \u001b[38;5;241m=\u001b[39m get_PCA(X_train, \u001b[38;5;241m0.95\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# plotting first 5 eigenfaces\u001b[39;00m\n\u001b[0;32m      3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_PCA' is not defined"
     ]
    }
   ],
   "source": [
    "_, eigenfaces = get_PCA(X_train, 0.95)\n",
    "# plotting first 5 eigenfaces\n",
    "fig, axs = plt.subplots(1, 5, figsize=(16, 10))\n",
    "for i in range(5):\n",
    "    image_array = np.reshape(eigenfaces[:, i], (image_height, image_width))\n",
    "    axs[i].imshow(image_array, cmap=\"gray\")\n",
    "    axs[i].set_title(\"Eigenface \" + str(i + 1))\n",
    "    axs[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b68a9f",
   "metadata": {},
   "source": [
    "## Test PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_PCA(training_data,testing_data,training_labels,testing_labes,alpha, k):\n",
    "    mean_face, eigenfaces = get_PCA(training_data, alpha)\n",
    "    X_train_pca, X_test_pca = PCA_Projected_data(training_data,testing_data,mean_face, eigenfaces)\n",
    "    knn = KNeighborsClassifier(k, weights=\"distance\")\n",
    "    knn.fit(X_train_pca, training_labels.ravel())\n",
    "    y_pred = knn.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(testing_labes, y_pred.ravel())\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(\"PCA Accuracy: \" + str(Test_PCA(X_train,X_test,y_train,y_test,0.85, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd6849",
   "metadata": {},
   "source": [
    "## Classifier Tuning for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc31096",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.8, 0.85, 0.9, 0.95]\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "df = pd.DataFrame(index=alphas, columns=k_values)\n",
    "for num_dominant_eigen_vectors in alphas:\n",
    "    for k in k_values:\n",
    "        accuracy = Test_PCA(X_train,X_test,y_train,y_test,num_dominant_eigen_vectors, k)\n",
    "        df.loc[num_dominant_eigen_vectors, k] = accuracy\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206363fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    plt.plot(df.index, df[k], marker=\"o\", label=f\"k={k}\")\n",
    "\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for different alphas and k values\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9ff7d",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LDA(X_train, y_train):\n",
    "    y_train = np.squeeze(y_train)\n",
    "    class_means = np.array([np.mean(X_train[y_train == i], axis=0) for i in range(1, 41)])\n",
    "    class_sizes = np.array([np.sum(y_train == i) for i in range(1, 41)])\n",
    "\n",
    "    # Compute overall mean\n",
    "    overall_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "    # Compute within-class scatter matrix\n",
    "    S_W = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "    for i in range(1, 41):\n",
    "        # Use boolean index to select rows from X_train\n",
    "        class_data = X_train[y_train == i]\n",
    "        centered_data = class_data - class_means[i - 1]\n",
    "        S_W += np.dot(centered_data.T, centered_data) \n",
    "\n",
    "    # # Regularize S_W\n",
    "    S_W += 1e-7 * np.identity(X_train.shape[1])\n",
    "\n",
    "    # Compute between-class scatter matrix\n",
    "    S_B = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "    for i in range(1, 41):\n",
    "        # Use boolean index to select rows from X_train\n",
    "        class_data = X_train[y_train == i]\n",
    "        class_diff = class_means[i - 1] - overall_mean\n",
    "        S_B += class_sizes[i - 1] * np.outer(class_diff, class_diff)\n",
    "\n",
    "    # Solve generalized eigenvalue problem\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(np.dot(np.linalg.inv(S_W), S_B))\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # Take only the dominant eigenvectors\n",
    "    projection_matrix = sorted_eigenvectors[:, :39]\n",
    "    return np.real(projection_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b62efc",
   "metadata": {},
   "source": [
    "## The Projection matrix of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_projection_matrix = get_LDA(X_train,y_train)\n",
    "print(LDA_projection_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA PRojection\n",
    "\n",
    "def LDA_projected_data(training_data,test_data,projection_matrix):\n",
    "    projected_X_train = np.dot(training_data, projection_matrix)\n",
    "    projected_X_test = np.dot(test_data, projection_matrix)\n",
    "    return projected_X_train, projected_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ed68ac",
   "metadata": {},
   "source": [
    "## Test LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ccd8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_LDA(k):\n",
    "    projected_X_train, projected_X_test = LDA_projected_data(X_train,X_test,LDA_projection_matrix)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(projected_X_train, y_train.ravel())\n",
    "    y_pred = knn.predict(projected_X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred.ravel())\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(\"LDA Accuracy: \" + str(Test_LDA(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f07f1d",
   "metadata": {},
   "source": [
    "## Classifier Tuning for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "projected_X_train, projected_X_test = LDA_projected_data(X_train,X_test,LDA_projection_matrix)\n",
    "# Loop over the values of k\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    knn.fit(projected_X_train, y_train.ravel())\n",
    "    y_pred = knn.predict(projected_X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred.ravel())\n",
    "    results.append({\"accuracy\": accuracy})\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results, index=k_values)\n",
    "df.index.name = \"k\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df, marker=\"o\")\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for different k values\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc44c0a",
   "metadata": {},
   "source": [
    "# Comparison between PCA and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294e574",
   "metadata": {},
   "source": [
    "### Accuracy of PCA vs LDA w.r.t k (number of nearest neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464235c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.8, 0.85, 0.9, 0.95]\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "variants = [\n",
    "    \"PCA α = 0.8\",\n",
    "    \"PCA α = 0.85\",\n",
    "    \"PCA α = 0.9\",\n",
    "    \"PCA α = 0.95\",\n",
    "    \"LDA\",\n",
    "]\n",
    "df = pd.DataFrame(index=variants, columns=k_values)\n",
    "for num_dominant_eigen_vectors in alphas:\n",
    "    for k in k_values:\n",
    "        for i in range(4):\n",
    "            pca_accuracy = Test_PCA(X_train,X_test,y_train,y_test,alpha[i], k)\n",
    "            df.loc[variants[i], k] = str(pca_accuracy * 100) + \"%\"\n",
    "        lda_accuracy = Test_LDA(k)\n",
    "        df.loc[\"LDA\", k] = str(lda_accuracy * 100) + \"%\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf2cbe",
   "metadata": {},
   "source": [
    "## Splitting Test and Train Data (70-30 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27819ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,labels):\n",
    "    bonus_x_train = np.zeros((280,10304))\n",
    "    bonus_x_test = np.zeros((120,10304))\n",
    "    bonus_y_train = np.zeros((280,1))\n",
    "    bonus_y_test = np.zeros((120,1))\n",
    "    # split each person's data into 7 training images and 3 testing images\n",
    "    for  i in range (40):\n",
    "        bonus_x_train[i*7:(i+1)*7] = data[i*10:i*10+7]\n",
    "        bonus_x_test[i*3:(i+1)*3] = data[i*10+7:i*10+10]\n",
    "        bonus_y_train[i*7:(i+1)*7] = labels[i*10:i*10+7]\n",
    "        bonus_y_test[i*3:(i+1)*3] = labels[i*10+7:i*10+10]\n",
    "    # shuffle the data\n",
    "    indices = np.arange(280)\n",
    "    np.random.shuffle(indices)\n",
    "    bonus_x_train = bonus_x_train[indices]\n",
    "    bonus_y_train = bonus_y_train[indices]   \n",
    "    return bonus_x_train,bonus_x_test,bonus_y_train,bonus_y_test\n",
    "bonus_x_train,bonus_x_test,bonus_y_train,bonus_y_test = split_data(Data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_x_train, bonus_x_test, bonus_y_train, bonus_y_test = split_data(Data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_face, eigenfaces = get_PCA(bonus_x_train, 0.85)\n",
    "X_train_pca, X_test_pca = PCA_Projected_data(bonus_x_train,bonus_x_test,mean_face, eigenfaces)\n",
    "knn = KNeighborsClassifier(1, weights=\"distance\")\n",
    "knn.fit(X_train_pca, bonus_y_train.ravel())\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "accuracy = accuracy_score(bonus_y_test, y_pred.ravel())\n",
    "print(\"PCA Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7234f",
   "metadata": {},
   "source": [
    "## Comaprison between Oridinary Split and Train SPlit in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.8, 0.85, 0.9, 0.95]\n",
    "k=1\n",
    "df = pd.DataFrame(index=alpha, columns=[\"Original Split\", \"Bonus Split\"])\n",
    "for num_dominant_eigen_vectors in alpha:\n",
    "    pca_accuracy = Test_PCA(X_train,X_test,y_train,y_test,num_dominant_eigen_vectors, k)\n",
    "    df.loc[num_dominant_eigen_vectors, \"Original Split\"] = pca_accuracy\n",
    "    bonus_pca_accuracy = Test_PCA(bonus_x_train,bonus_x_test,bonus_y_train,bonus_y_test,num_dominant_eigen_vectors, k)\n",
    "    df.loc[num_dominant_eigen_vectors, \"Bonus Split\"] = bonus_pca_accuracy\n",
    "df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the df as\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "df.plot(kind=\"bar\", ax=ax[0])\n",
    "df.plot(kind=\"line\", ax=ax[1], marker=\"o\")\n",
    "ax[0].set_title(\"Bar Chart\")\n",
    "ax[1].set_title(\"Line Chart\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd487fb1",
   "metadata": {},
   "source": [
    "## Comparison between Ordinart SPlit and Bonus SPlit in LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(X_train, X_test, y_train, y_test, k):\n",
    "    knn = KNeighborsClassifier(k, weights=\"distance\")\n",
    "    knn.fit(X_train, y_train.ravel())\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred.ravel())\n",
    "    return accuracy\n",
    "Bonus_LDA_projection_matrix = get_LDA(bonus_x_train, bonus_y_train)\n",
    "projected_X_train, projected_X_test = LDA_projected_data(bonus_x_train,bonus_x_test,LDA_projection_matrix)\n",
    "acc_Lda_07 = get_acc(projected_X_train, projected_X_test, bonus_y_train, bonus_y_test, 1)\n",
    "print(\"LDA Accuracy: \" + str(acc_Lda_07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=[], columns=[\"Original Split\", \"Bonus Split\"])\n",
    "df.loc[\"LDA\", \"Original Split\"] = Test_LDA(1)\n",
    "df.loc[\"LDA\", \"Bonus Split\"] = acc_Lda_07\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dde892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\")\n",
    "plt.title(\"LDA Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c262bc8",
   "metadata": {},
   "source": [
    "# Variants of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97fe2d",
   "metadata": {},
   "source": [
    "## Polynomial Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37863fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Polynomial_Kernel_PCA(no_of_components, k):\n",
    "    kpca = KernelPCA(n_components=no_of_components, kernel=\"poly\")\n",
    "    X_train_kpca = kpca.fit_transform(X_train)\n",
    "    X_test_kpca = kpca.transform(X_test)\n",
    "    knn = KNeighborsClassifier(k, weights=\"distance\")\n",
    "    knn.fit(X_train_kpca, y_train.ravel())\n",
    "    y_pred = knn.predict(X_test_kpca)\n",
    "    accuracy = accuracy_score(y_test, y_pred.ravel())\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(\"Polynomial Kernel PCA Accuracy: \" + str(Test_Polynomial_Kernel_PCA(36, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4652c1",
   "metadata": {},
   "source": [
    "## Comparison between Polynomial Kernel PCA and My Amazing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5510d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Normal PCA\", \"Polynomial Kernel PCA\"]\n",
    "values = [Test_PCA(0.8, 1), Test_Polynomial_Kernel_PCA(36, 1)]\n",
    "\n",
    "# Create bar chart\n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Variants of PCA\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Comparison between Normal PCA and Polynomial Kernel PCA\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088de423",
   "metadata": {},
   "source": [
    "# Variants of LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623abb0",
   "metadata": {},
   "source": [
    "## Shrinkage LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Shrinkage_LDA(k):\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"eigen\", shrinkage=\"auto\")\n",
    "    lda.fit(X_train, y_train.ravel())\n",
    "    X_train_projection = lda.transform(X_train)\n",
    "    X_test_projection = lda.transform(X_test)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_projection, y_train.ravel())\n",
    "    y_pred = knn.predict(X_test_projection)\n",
    "    accuracy = accuracy_score(y_test, y_pred.ravel())\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(\"Shrinkage LDA Accuracy: \" + str(Test_Shrinkage_LDA(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18279a",
   "metadata": {},
   "source": [
    "## Comparison between Shrinkage LDA and Normal LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b393007",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Normal LDA\", \"Shrinkage LDA\"]\n",
    "values = [Test_LDA(1), 0.95]\n",
    "\n",
    "# Create bar chart\n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Variants of LDA\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Comparison between Normal LDA and Shrinkage LDA\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42f7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27339ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e1d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
